---
title: "Cerrado Project - 16S rRNA analysis"
author: "Alonna Wright"
date: "September 7, 2018"
output:
  html_document: default
  pdf_document: default
---

---
title: "Cerrado Project - 16S rRNA Analysis"
author: "Alonna Wright"
date: "September 7, 2018"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The following code originated from the [dada2 pipeline tutorial](https://benjjneb.github.io/dada2/tutorial.html), unless otherwise noted.

## Installing and loading necessary packages

```{r install_packages}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("IRanges", version = "3.8")
BiocManager::install("Biostrings", version = "3.8")
BiocManager::install("rhdf5", version = "3.8")
source("https://bioconductor.org/biocLite.R")
biocLite()
biocLite("dada2")
biocLite("rhdf5")
biocLite("phyloseq")
biocLite("metagenomeSeq")
biocLite("IRanges")
biocLite("msa")
install.packages("devtools")
install.packages("tidyverse")
install.packages("dplyr")
install.packages("ps")
install.packages("phangorn")
install.packages("TITAN2")
install.packages("labdsv")
install.packages("tidyselect")
install.packages("randomForest")
install.packages("plyr")
install.packages("rfUtilities")
install.packages("caret")
install.packages("e1071")
install.packages("RColorBrewer")
devtools::install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")

```

```{r load_libraries} 
message = FALSE

library(devtools)
library(dada2)
library(phyloseq)
library(vegan)
library(ggplot2)
library(data.table)
library(devtools)
library(knitr)
library(RVAideMemoire)
library(plyr)
library(dplyr)
library(grid)
library(metagenomeSeq)
library(pairwiseAdonis)
library(phangorn)
library(msa)
library(labdsv)
library(TITAN2)
library(tidyselect)
library(randomForest)
library(plyr)
library(rfUtilities)
library(caret)
library(e1071)
library(RColorBrewer)
```

# 16S sequence Pre-processing 

Designate the directory in which you'll be working in, this should be the one that contains your sequencing data. Confirm your in the correct directory and all of your files are present by listing the files in the working directory. 

```{r set_directory}
path <- "/Users/Alonna/Desktop/Grad_School/Rodrigues Lab Dissertation Work/AW_CerradoProject/CerradoProjectRMD/Cerrado16SAnalysis"
setwd(path)
list.files(path)
```
Even though our files are compressed into .gz format, there is no need to unzip them.

## Sorting .fastq files by forward and reverse

Separating sequencing files by forward or reverse reads. The naming pattern indicates whether a file is a forward (R1) or a reverse (R2), so we'll make two different lists by recognizing that pattern. 

```{r fwdrev_sort}
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq", full.names=TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq", full.names=TRUE))

```

Sample names are also indicated in the file names, so we'll extract those as well. 

```{r extract_filenames}
sample.names <- sapply(strsplit(basename(fnFs), "_"), '[', 1)
```

## Visualizing quality of the forward and reverse reads

Knowing how high of quality our reads are will help inform where (and if) to trim the reads to only work with high quality sequences. 

###Forward Read Quality
```{r fwd_qualityplot}
plotQualityProfile(fnFs[1:10])
```
Since these forward reads look relatively high quality, we'll only trim the last 10bp off. 

###Reverse Read Quality
```{r rev_qualityplot}
plotQualityProfile(fnRs[1:10])
```

These reads start to lose their quality toward the end of the sequences, so we'll trim off 175bp off the end.  When trimming, you must make sure that your reads still have enough overlap between forward and reverse. 

## Filter and Trim

Create a directory where filtered files will be stored, and designate names for these new filtered files. 

```{r filt_sort}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))

```

Using the information gathered from the quality reads above, the files will be trimmed. 240 base length for forward reads, 175 base length for reverse reads, no ambiguous bases, and truncated after the first instance of a base quality less than or equal to Q=2.

```{r filtertrim}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,175),
                     maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, 
                     compress = TRUE, multithread = FALSE) #On Windows set multithread = FALSE
head(out)
cat("Total reads (in, out) =", colSums(out, na.rm = FALSE, dims=1), "Mean reads = (in, out)", colMeans(out, na.rm = FALSE, dims=1))

```

##Learning error rates

This step trains the alogirthm to learn the errors of the reads.  (This step is computationally intensive if you're on a personal computer)
```{r learnerrors}
errF <- learnErrors(filtFs, multithread = TRUE, nbases = 1e+15)
errR <- learnErrors(filtRs, multithread = TRUE, nbases = 1e+15)

```

Now, we want to visualize those errors. Ideally, the consensus quality score would line up with the red ideal line, but these results are relatively close. 

```{r ploterrors}
warning = FALSE

plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)

```

##Dereplicating fastq files

```{r derep}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
```

```{r }
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

## dada2 
Sequences are now put through the dada2 algorithm to determine their exact sequence variants.

```{r dada}
dadaFs <- dada(derepFs, err=errF, multithread = TRUE)
dadaRs <- dada(derepRs, err=errR, multithread = TRUE)
dadaFs[[1]]
```
 
 Now we merge the forward and reverse pairs of the exact sequence variants. 
 
```{r mergepairs}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)


head(mergers[[1]])
```
 
 ## Generating sequence table 
 Here the sequence table is generated and restricted to only those sequences that fall in the range of 249bp to 258bp, since the target sequence length is 250bp.
 
```{r seqtable}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
table(nchar(getSequences(seqtab)))
seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(249,258)]
```
 
 ## Remove any chimeras
```{r removechimeras}
seqtab.nochim <- removeBimeraDenovo(seqtab2, method = "consensus", multithread = TRUE, verbose = TRUE)
dim(seqtab.nochim)
cat("Ratio of sequences without chimeras to all sequences =", sum(seqtab.nochim)/sum(seqtab2))
cat("\nTotal number of unique features = ", sum(seqtab.nochim))
```
 The ratio all sequnces to the subset without chimeras determined that approximately 10.7% (1 - ratio * 100) of the total sequences are accounted for by chimeras. 
 
## Tracking sample numbers through the quality control processes

```{r tracksamples}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

 
##Assign taxonomy

```{r assigntaxonomy}
taxa <- assignTaxonomy(seqtab.nochim, "/Users/Alonna/Desktop/Grad_School/Rodrigues Lab Dissertation Work/AW_CerradoProject/CerradoProjectRMD/silva_nr_v132_train_set.fa.gz", multithread=TRUE)

```

```{r addSpecies}
taxa <- addSpecies(taxa, "/Users/Alonna/Desktop/Grad_School/Rodrigues Lab Dissertation Work/AW_CerradoProject/CerradoProjectRMD/silva_species_assignment_v132.fa.gz")
```
##Create a Phylogenetic Tree
```{r}
# seqs <- getSequences(seqtab)
# names(seqs) <- seqs # This propagates to the tip labels of the tree
# mult <- msa(seqs, method="ClustalW", type="dna", order="input")
```


#Phyloseq Analysis

Using the data generated from the dada2 pipeline, a phyloseq object was created for further analysis. 

```{r phyloseq_object}
metadata <- read.csv2("AW_Metadata_AllDataIncluded_100718.csv", header=TRUE, sep = ",", fileEncoding="UTF-8-BOM")

rownames(metadata) <- paste0(metadata$SampleID)
rownames(seqtab.nochim) <- sapply(strsplit(row.names(seqtab.nochim), "_"), '[', 1)

ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
                  sample_data(metadata), 
                  tax_table(taxa))
```

##Exact Sequence Variant (ESV) values
For each unqiue ESV, the abundance is recorded.  This number is calculated as a sum of ESV occurence across all samples. 
```{r esv_values }
taxacounts <- as.matrix(taxa_sums(ps))
```

##Shannon diversity index
This calculates the Shannon richness for each individual sample and returns that value to a table. Richness can only be calculated on integers. Normalization introduces decimal counts, so this has to be calculated with the original, non-normalized, phyloseq object. 
```{r shannon_diversity}
tab <- estimate_richness(ps, split = TRUE, measures = "Shannon")

alpha_tab <- cbind(tab, soil_type = metadata$soil_type [match(rownames(tab), rownames(metadata))])
alpha_tab <- cbind(alpha_tab, year = metadata$year [match(rownames(tab), rownames(metadata))])
alpha_tab <- cbind(alpha_tab, soil_year = metadata$soil_year [match(rownames(tab), rownames(metadata))])

hist(alpha_tab$Shannon)

ggplot(alpha_tab,
       aes(x = soil_type, y=Shannon, fill=soil_type)) +
  ggtitle("Shannon Alpha Diversity Measures") +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha=0.5, size=2, pch=21) +
  xlab("") +
  ylab("Alpha Diversity Measure") +
  # theme_bw()+
  theme(text = element_text(face = "bold", size=12, color = "black"), legend.position="none", 
        axis.text.x = element_text(angle = 0, hjust = 0.5, size=12, color = "black"), 
        axis.text.y = element_text(size=12, color = "black"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"))+
  scale_fill_brewer(palette = "Dark2", name = "Soil Type")


```


This error message is occuring because DADA2 as an algorithm does not call singletons, "due to the difficulty of differentiating rare singleton errors from real singleton variants" (from DADA2's creator, https://github.com/benjjneb/dada2/issues/214).  Since Shannon richness does not rely heavily on singletons, this is fine to ignore and move forward. 

Since this histogram is skewed to the left, the distribution isn't normal, and therefore ANOVA is not the optimal test.  We will opt for using the Kruskal-Wallis test. 


##metagenomeSeq normalization

Here the phyloseq object is transformed into a metagenomeSeq object for normalization.  The normalization factor is calculated, and then applied to the object. A matrix of these normalized values are then output for futher analysis. This is performed rather than rareification, to preserve the diversity of the dataset.

```{r metagenomeSeq_normalization}
ps.ms <- phyloseq_to_metagenomeSeq(ps)

ps.ms_normfactor <- cumNormStat(ps.ms)
cat("Normalization factor =", ps.ms_normfactor)
ps.ms.norm <- cumNorm(ps.ms, p = ps.ms_normfactor)
normalizedMatrix <- MRcounts(ps.ms.norm, norm = TRUE)
```

###Normalized phyloseq object
Now the object that was normalized above will be integrated into a new phyloseq object
```{r normalized_phyloseq}
ps_trans <- ps
otu_table(ps_trans) <- otu_table(normalizedMatrix, taxa_are_rows = TRUE)
```



#Statistical Analysis

##PERMANOVA using adonis

Since there are some variables that are do not contain data for some samples, all statistical analyses must be preceded by a subsetted table for that variable, to only test samples who have values for that variable. Since reveg samples are the only ones with  flora data, we will subset those to come back to later. Since there is a large chunk of data missing for 2005, this applies as well. 

```{r metadata subsetting}
metadata_reveg_subset <- metadata[complete.cases(metadata$C3_herbs),]

metadata_no2005 <- metadata[metadata$year != "2005",]

ps_trans_completeVariables <- ps_trans
sample_data(ps_trans_completeVariables) <- sample_data(metadata_no2005)

ps_trans_completeVariables@sam_data[["time_since_restoration"]] <- NULL
ps_trans_completeVariables@sam_data[["C3_herbs"]] <- NULL
ps_trans_completeVariables@sam_data[["C3_woody"]] <- NULL
ps_trans_completeVariables@sam_data[["C4_invasive"]] <- NULL
```



```{r adonis}
adonis(phyloseq::distance(ps_trans_completeVariables, method="bray") ~ soil_type, data = metadata_no2005, permutations = 10000)
adonis(phyloseq::distance(ps_trans_completeVariables, method="bray") ~ year, data = metadata_no2005, permutations = 10000)
```


## Pairwise permanova

```{r pairwise permanova by soil type}
micro.dist<-vegdist(decostand(normalizedMatrix, method="hellinger"), method="bray")

pairwise.perm.manova(micro.dist, metadata$soil_type, p.method="fdr")
```

```{r pairwise permanova by year}
pairwise.perm.manova(micro.dist, metadata$year, p.method="fdr")
```

```{r pairwise permanova by soil and year}
pairwise.perm.manova(micro.dist, metadata$soil_year, p.method="fdr")
```


##IndVal - Significant ESV determination

```{r generate.tax.summary function}
generate.tax.summary<-function(otu, tax.table) {
  tax2.summary<-as.data.frame(apply((apply(otu, 1, function(x) by(x, tax.table$Phylum, sum))), 2, function(x){x/sum(x)}))
  tax3.summary<-as.data.frame(apply((apply(otu, 1, function(x) by(x, tax.table$Class, sum))), 2, function(x){x/sum(x)}))
  tax4.summary<-as.data.frame(apply((apply(otu, 1, function(x) by(x, tax.table$Order, sum))), 2, function(x){x/sum(x)}))
  tax5.summary<-as.data.frame(apply((apply(otu, 1, function(x) by(x, tax.table$Family, sum))), 2, function(x){x/sum(x)}))
  tax6.summary<-as.data.frame(apply((apply(otu, 1, function(x) by(x, tax.table$Genus, sum))), 2, function(x){x/sum(x)}))
  return(list(Phylum=tax2.summary, Class=tax3.summary, Order=tax4.summary, Family=tax5.summary, Genus=tax6.summary))
}

```

```{r phylogeneticSummaries}
normalizedMatrix_sampleaAreRows <- t(normalizedMatrix)

micro.tax.summary<-generate.tax.summary(otu=as.data.frame(normalizedMatrix), tax.table=as.data.frame(taxa))

micro.species<-micro.tax.summary$Species
micro.genera<-micro.tax.summary$Genus
micro.class<-micro.tax.summary$Class
micro.family<-micro.tax.summary$Family
micro.order<-micro.tax.summary$Order
micro.phylum<-micro.tax.summary$Phylum
```


```{r indval}
#crashes R session for some reason
#indval.reveg <- as.data.frame(indval(micro.family, metadata$soil_type, numitr=1000))
```

Still trying to get this one to work as well, as of 1/18/19
```{r indval_titan2}
reveg_grp <- read.csv2("Reveg_grp_indval.csv", header=TRUE, sep = ",", fileEncoding="UTF-8-BOM")
rownames(reveg_grp) <- reveg_grp[,1]
reveg_grp["SampleID"] <- NULL

soil_grp <- read.csv2("Soil_grp_indval.csv", header=TRUE, sep = ",", fileEncoding="UTF-8-BOM")
substrate_grp <- read.csv2("Substrate_grp_indval.csv", header=TRUE, sep = ",", fileEncoding="UTF-8-BOM")

combined_grp <- as.matrix(read.csv2("Combined_grp_indval.csv", header=TRUE, sep = ",", fileEncoding="UTF-8-BOM"))
rownames(combined_grp) <- combined_grp[,1]
combined_grp["SampleID"] <- NULL

invalp_family_output <- TITAN2:::indvalp(combined_grp, as.matrix(t(micro.family)))
invalp_order_output <- TITAN2:::indvalp(combined_grp, as.matrix(t(micro.order)))
invalp_genera_output <- TITAN2:::indvalp(combined_grp, as.matrix(t(micro.genera)))
invalp_phylum_output <- TITAN2:::indvalp(combined_grp, as.matrix(t(micro.phylum)))

# indval_family_output <- TITAN2:::indval(reveg_grp, as.matrix(t(micro.family)), allscores = FALSE)

getivz_family_output <- TITAN2:::getivz(as.matrix(combined_grp_test), as.matrix(t(micro.family)), ivTot = FALSE, nPerm = 250, numClass = 3, imax = TRUE) 
```
It seems as if there are no indicator species for this set. Unsure if these results are from code error or true result. Still working on this issue.

#Graphing
Significance is not automatically denoted on the images, and will be added post generation, based off the results of the statistics above. To generate an SVG from this code put in the following code at the beginning of the graphing code, followed by dev.off() immediately following the graphing code.

svg(file="Name.svg",
    width=5,height=6,bg = "transparent")

## Plotting Stacked Bar Plot
```{r stackedbarplot}
TopNOTUs = names(sort(taxa_sums(ps_trans), TRUE)[1:50])

ent10 = prune_taxa(TopNOTUs, ps_trans)
phylumGlommed = tax_glom(ent10, "Phylum")

plot_bar(phylumGlommed, x="soil_year", fill="Phylum") + 
  facet_grid(~soil_type, scales = "free") +
  xlab("Year") +
  ggtitle("Phylum Abundance")+
 scale_x_discrete(labels = c("1997", "2002", "2003", "2005", "2008", "2011", "2015"))


```



## Beta Diversity 


```{r total ordination}
ordBC = ordinate(ps_trans, method = "NMDS", distance = "bray")
```



```{r plot total ordination}
plot_ordination(ps_trans, ordBC, color = "soil_type") + 
  geom_point(mapping = aes(shape = soil_type), size = 5) +
  ggtitle("Bray Curtis NMDS for all Soil Types") +
  scale_shape_discrete(name = "Soil Type") +
  scale_color_brewer(palette = "Dark2", name = "Soil Type")
```

```{r}
ps_trans@sam_data[["year"]] <- as.integer(ps_trans@sam_data[["year"]])
plot_ordination(ps_trans, ordBC, color = "soil_type") + 
  geom_point(mapping = aes(size = year)) +
  ggtitle("Bray Curtis NMDS for all Soil Types by Year") +
  scale_color_brewer(palette = "Dark2", name = "Soil Type")+
  scale_size_continuous(name = "Year", labels = c("1997", "2002", "2003", "2005", "2008", "2011", "2015")) 
```

## Subset phyloseq objects by soil type

```{r}

ps.reveg <- subset_samples(ps_trans, soil_type=="Revegetation")
ps.soil <- subset_samples(ps_trans, soil_type=="Soil")
ps.substr <- subset_samples(ps_trans, soil_type=="Substrate")
```


### Soil Bray-Curtis
```{r soil_NMDS}

#By Soil - Calculations of Bray-Curtis distances
bray.soil <- phyloseq::distance(ps.soil, method = "bray")

md.sample.type.soil <- data.frame(sample_data(ps.soil))
bd.soil <-betadisper(bray.soil, md.sample.type.soil$year) 
permutest(bd.soil)

#NMDS of B-C distances of Soil by Year
plot(bd.soil,
     main = "Bray Distances of Soil by Year")


```

```{r soil_boxplotTukey}
boxplot(bd.soil)
TukeyHSD(bd.soil)
```

```{r soil_dataframe}
plot.bd.soil <- data.frame(bd = bd.soil$distances)
plot.bd.soil$year <- bd.soil$group
plot.bd.soil$Sample.type <- "Soil"
```

```{r soil_linearmodel}
soil_lm <-lm(bd ~ year, data = plot.bd.soil)
plot(soil_lm)
```

### Revegetation Bray-Curtis

```{r reveg_NMDS}
bray.reveg <- phyloseq::distance(ps.reveg, method = "bray")
md.sample.type.reveg <- data.frame(sample_data(ps.reveg))
bd.reveg <-betadisper(bray.reveg, md.sample.type.reveg$year) #bray distances of reveg 
permutest(bd.reveg)

plot(bd.reveg,
     main = "Bray Distances of Revegetation by Year")

```

```{r reveg_boxplotTukey}
boxplot(bd.reveg)
TukeyHSD(bd.reveg)
```

```{r reveg_dataframe}
plot.bd.reveg <- data.frame(bd = bd.reveg$distances)
plot.bd.reveg$year <- bd.reveg$group
plot.bd.reveg$Sample.type <- "Revegetation"
```

```{r reveg_linearmodel}
reveg_lm <-lm(bd ~ year, data = plot.bd.reveg) #linear model - if data has normal distribution
plot(reveg_lm)
```

### Substrate Bray-Curtis

```{r substrate_NMDS}
bray.substr <- phyloseq::distance(ps.substr, method = "bray")
md.sample.type.substr <- data.frame(sample_data(ps.substr))
bd.substr <- betadisper(bray.substr, md.sample.type.substr$year) #bray distances of substr 
permutest(bd.substr)

plot(bd.substr,
     main = "Bray Distances of Substrate by Year")
```

```{r substrate_boxplotTukey}
boxplot(bd.substr)
TukeyHSD(bd.substr)
```

```{r substrate_dataframe}
plot.bd.substr <- data.frame(bd = bd.substr$distances)
plot.bd.substr$year <- bd.substr$group
plot.bd.substr$Sample.type <- "Substrate"

```

```{r substrate_linearmodel}
substrate_lm <-lm(bd ~ year, data = plot.bd.substr) 
plot(substrate_lm)
```

##Merged Bray-Curtis analyses

###Merging the individual data frames back together. 
```{r merged_BrayCurtis}
plot.bd.merged <- rbind(plot.bd.soil, plot.bd.reveg, plot.bd.substr)

aggregate(bd ~ Sample.type + year, data = plot.bd.merged, mean)
```

###Kruskal Tests on Bray-Curtis values

```{r kruskal_BrayCurtis}

kruskal.test(Sample.type ~ bd, data = plot.bd.merged)
kruskal.test(year ~ bd, data = plot.bd.merged)
```

###Wilcox Test
```{r wilcox_BrayCurtis}
pairwise.wilcox.test(plot.bd.merged$bd, 
                     plot.bd.merged$Sample.type,
                     p.adjust.method = "BH")
```


## NMDS with radiating vectors of significant variables

### Revegetation NMDS with Vectors
This only ends up keeping the revegetation samples, since they are the only ones that underwent every analysis. 

```{r message=FALSE}
variables <- dplyr::select(metadata, SampleID, water_pH, CaCl2_pH, organic_matter, Available.P, Remaining.P, potassium, Kcmol, sulfur, calcium, magnesium, aluminum, acidity_potential, Na_CTC, percent_V, percent_m, Ca_Mg, Ca_K, Mg_K, Ca_CEC, Mg_CEC, K_CEC, H.Al_T, Na_CTC, boron, zinc, iron, manganese, copper, total_nitrogen, course_sand, fine_sand, silt, clay, d13C, percent_C, percent_vol, percent_dC3, percent_dC4, macroaggregates_percent, ugg_fraction_percent, s_and_c_fraction_percent, r_fraction_percent, sum_percent)

variables <- dplyr::select(variables, -c(SampleID))

variables_numeric <- sapply(variables, as.numeric)
row.names(variables_numeric) <- rownames(variables) 


variables_complete <- variables[complete.cases(variables),]

nmds.ord = phyloseq::ordinate(ps_trans, method = "NMDS", distance = "bray")
nmds.ord.scores <- scores(nmds.ord, display="sites")
nmds.ord.complete <- as.data.frame(nmds.ord.scores[rownames(nmds.ord.scores) %in% rownames(variables_complete),])


#ENVFIT to correlate variables to distance matrix
fit <- envfit(nmds.ord.complete, variables_complete, permutations = 999, na.rm=TRUE)
scores(fit, "vectors")
fit



#Transform envfit object into a dataframe that can be used in ggplot, at the same time select only the vectors that are significant (p value less than 0.5)
A <- as.list(fit$vectors)
pvals <- as.data.frame(A$pvals)
arrows <- as.data.frame(A$arrows*sqrt(A$r))
C <- cbind(arrows, pvals)
V <- subset(C, pvals<0.05)
V <- cbind(V, Species = rownames(V))


ggplot(data = nmds.ord.complete, aes(NMDS1, NMDS2)) + 
  geom_point(mapping = aes(shape = soil_type),size = 5) +
  geom_segment(data=V,aes(x=0,xend=NMDS1,y=0,yend=NMDS2),
               arrow = arrow(length = unit(0.5, "cm")),colour="grey") + 
  geom_text(data=V,aes(x=NMDS1,y=NMDS2,label=Species),size=3)+
  ggtitle("Revegetation NMDS plot with Significance Vectors") +
  scale_color_brewer(palette = "Dark2", name = "Soil Type")+
  guides(shape = guide_legend(title="Management")) +
  #guides(color = guide_legend(title="Management")) +
  coord_fixed()

```

## Analysis with all samples, not just those with complete variables. 

```{r message=FALSE}
variables <- dplyr::select(metadata, SampleID, water_pH, CaCl2_pH, organic_matter, Available.P, Remaining.P, potassium, Kcmol, sulfur, calcium, magnesium, aluminum, acidity_potential, Na_CTC, percent_V, percent_m, Ca_Mg, Ca_K, Mg_K, Ca_CEC, Mg_CEC, K_CEC, H.Al_T, Na_CTC, boron, zinc, iron, manganese, copper, total_nitrogen, course_sand, fine_sand, silt, clay, d13C, percent_C, percent_vol, percent_dC3, percent_dC4, macroaggregates_percent, ugg_fraction_percent, s_and_c_fraction_percent, r_fraction_percent, sum_percent)

variables <- dplyr::select(variables, -c(SampleID))

variables_numeric <- sapply(variables, as.numeric)
row.names(variables_numeric) <- rownames(variables) 

#This only ends up keeping the revegetation samples, since they are the only ones that underwent every analysis. 
#variables_complete <- variables[complete.cases(variables),]

nmds.ord = phyloseq::ordinate(ps_trans, method = "NMDS", distance = "bray")
nmds.ord.scores <- scores(nmds.ord, display="sites")
nmds.ord.noncomplete <- as.data.frame(nmds.ord.scores[rownames(nmds.ord.scores) %in% rownames(variables),])

nmds.ord.noncomplete <- cbind(nmds.ord.noncomplete, metadata[, "soil_type"][match(rownames(nmds.ord.noncomplete), rownames(metadata))])



#ENVFIT to correlate variables to distance matrix
fit <- envfit(nmds.ord.noncomplete, variables, permutations = 999)
scores(fit, "vectors")
fit



#Transform envfit object into a dataframe that can be used in ggplot, at the same time select only the vectors that are significant (p value less than 0.5)
A <- as.list(fit$vectors)
pvals <- as.data.frame(A$pvals)
arrows <- as.data.frame(A$arrows*sqrt(A$r))
C <- cbind(arrows, pvals)
V <- subset(C, pvals<0.05)
V <- cbind(V, Species = rownames(V))


ggplot(data = nmds.ord.noncomplete, aes(NMDS1, NMDS2)) + 
  geom_point(size = 5) +
  geom_segment(data=V,aes(x=0,xend=NMDS1,y=0,yend=NMDS2),
               arrow = arrow(length = unit(0.5, "cm")),colour="grey") + 
  geom_text(data=V,aes(x=NMDS1,y=NMDS2,label=Species),size=3)+
  ggtitle("Revegetation NMDS plot with Significance Vectors") + 
  guides(shape = guide_legend(title="Soil Type")) +
  guides(color = guide_legend(title="Soil Type")) +
  coord_fixed()

```

# Random Forest Analysis - Second Try

Random forest analysis to identify key OTUs by each site. Code and tutorial from https://rpubs.com/michberr/randomforestmicrobe, but not updated since 2015.

```{r pruning low abundance taxa}
cat(ntaxa(ps_trans), "OTUs in this phyloseq object")

cat("\nLibrary sizes of the samples within the normalized phyloseq object", "\nMean size:", mean(sample_sums(ps_trans)), "\nMinimum library size: ", min(sample_sums(ps_trans)), "\nMaximum library size: ", max(sample_sums(ps_trans)))


```
```{r}
prunescale = 0.0001
minlib = 4479

ps_trans_renamed <- ps_trans
taxa_names(ps_trans_renamed) <- paste0("OTU", 1:ntaxa(ps_trans_renamed))

tax.mean <- taxa_sums(ps_trans_renamed)/nsamples(ps_trans_renamed)
sites.prune <- prune_taxa(tax.mean > prunescale*minlib, ps_trans_renamed)
sites.prune
```


```{r define predictors}
predictors <- t(otu_table(sites.prune))
dim(predictors)
```

Make one column for the outcome/response variables, and then combine them into one data frame.
```{r response dataframe}
response <- as.factor(sample_data(sites.prune)$soil_type)

rf.data <- data.frame(response, predictors)
```

```{r training the random forest model}
set.seed(2)
soil_type.classify <- randomForest(response~., data = rf.data, ntree = 100)
print(soil_type.classify)

```

### Predictor data frame
Make a data frame with predictor names and their importance, then order them by importance and only select the top 20.
```{r predictor data frame}
imp <- importance(soil_type.classify)
imp <- data.frame(predictors = rownames(imp), imp)

imp.sort <- arrange(imp, desc(MeanDecreaseGini))
imp.sort$predictors <- factor(imp.sort$predictors, levels = imp.sort$predictors)

imp.20 <- imp.sort[1:20, ]

```

### Plot the predictors
```{r plotting predictors}
ggplot(imp.20, aes(x = predictors, y = MeanDecreaseGini)) +
  geom_bar(stat = "identity", fill = "indianred") +
  coord_flip() +
  ggtitle("Most important OTUs for classifying samples between soil types")
```

```{r table of predictors}
otunames <- imp.20$predictors
r <- rownames(tax_table(ps_trans_renamed)) %in% otunames
knitr::kable(tax_table(ps_trans_renamed)[r, ])
```


## Session Info
```{r}
sessionInfo()
```

